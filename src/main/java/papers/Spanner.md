# Spanner - Google全球分布式数据库

## 0 摘要
- 高可用，可伸缩，多版本，多副本同步
- 全球分布，支持外部一致性，和分布式事务
- 本文描述其特性，结构，设计原理和接口
- TODO: 暴露时钟不确定性
- 对现有数据的非阻塞读取，无锁只读事务，原子性模型修改

## 1 简述
- 数据分片只全球多个数据中心
- 跨多个Paxos状态机集合
- 客户端自动在多副本之间转移故障
- 数据总量和服务器数量发生变化是，自动重新分片
- 规模在百万台服务器，和万亿行数据库记录
- TODO： 应用程序选择低延迟而非高可用
- BigTable不适合不断演进的数据库模型，不支持强一致性
- MegaStore 支持半结构化数据模型和副本，但是写入慢
- Spanner从版本化键值数据库发展为多版本时态数据库
- 支持细粒度控制副本配置
- 用户距离控制读取延迟
- 副本距离控制写入延迟
- 副本数量控制可用性，持久性和读取性能


## TODO
- 外部一致性读写
- 某个时间戳上的全局一致性读取
- 一致性MapReduce执行
- 院子模型更新
- 外部一致性，线性一致性，一个事务先提交则时间戳小
- TrueTime API的实现，暴露了时钟的不确定性

## 0918

## 2 实现
- 使用抽象的目录来管理副本和局部性
- 一个Spanner的部署为Universe，全球大概几个Universe
- 每个Universe有一个master，一个放置驱动，若干区域集合
- 区域是物理隔离单位，有一个master和成百上千的Spanner服务器
- Universe master控制和显示所有区域的状态信息，可以交互调试
- 放置驱动每分钟检查需要一定的数据，完成区域迁移，保证负载均衡

## 2.1 Spanner 运行栈
- 多版本数据库（key: string, timestamp: int64) -> (value: string)
- Participant Leader -> Transaction Manager -> Lock Table -> Leader
- Replica -> Paxos -> Tablet (存在B树和WAL) -> Colossus / GFS
- Paxos状态机基于定时租约，只有为主的时候才可写，每个副本可读
- 副本之间用LockTable实现并发控制，包括两阶段锁，可事务性读取
- 副本之间使用事务管理器来支持分布式事务，Paxos Group使用两阶段提交


## 0920

## 2.2 目录放置
- 目录是桶，在键值集合的上层？一组前缀相同的连续的键的集合
- 2.3讲述前缀的来源，目录可以控制数据的局部性，尽量在数据中心内传输？
- 缓解Paxos组的负载而移动目录，即相同的连续的键放在一起
- 目录可以在客户端操作的时候移动，50MB的目录移动需要几秒
- 一个Paxos组包含多个目录，Spanner的tablet装有多个空间分区的容器
- Bigtable必须是行空间上字典顺序连续的分区
- 后台任务movedir，可以添加和删除副本，不是单个事务，避免阻塞
- 开始移动数据时注册时间，完成时启动事务原子性地移动剩余数据，更新组的元数据
- 目录还可以指定副本的地理位置，数量，类型，比如北美，五份副本，一份证人
- 应用程序给目录打上标签，保存各自的目录到不同的区域
- 目录太大还可以分成多个段，从而移动段而不是整个目录

## 0922

## 2.3 数据模型
- 模式化的半关系型表，支持查询语言和通用事务
- Megastore支持模式化的半关系型表和副本同步，Google or UCB?
- Bigtable 仅支持跨数据中心副本的最终一致性
- Megastore 比 Bigtable 简单，支持跨数据中心的副本同步，其他区别？
- 使用Megastore的系统有Gmail，Picasa，Calendar，Android Market, AppEngine
- Bigtable 缺少跨行事务，所以构建了Percolator
- Spanner的两阶段提交有性能问题，所以应用程序应该避免多度使用事务
- 一个宇宙有多个数据库，一个库有无限个表，每个表和行，列和版本号
- Spanner并非纯关系型，每行有行名作为主键
- TODO:多个有层次结构的表，交错结构

## 3 TrueTime 接口
- TrueTimeInterval，一个有时间不确定界限的时间方位，注意是不确定
- TT.now() 被调用的时绝对时间，带有闰秒的Unix时间
- 底层使用GPS和原子时钟，GPS信号弱要用天线，原子时钟不是很贵
- 后台使用Marzullo算法的变体检测时间错误的机器， TODO

## 4 并发控制
- 如何实现，外部一致事务，无锁只读事务，旧数据的非阻塞读取
- 不同区Spanner客户端的写去，两阶段提交会在准备阶段生成Paxos写入
- 读写事务，单独的写入，客户端无需循环等待
- 只读事务，单独的非快照读，无锁执行，不会阻塞写，
- 快照读取，旧数据的无锁读取

## 0924

### 4.2.1 读写事务
- 和Bigtable一样，事务的写入操作在提交之前会在客户端缓存
- 读取操作可以从客户端直接读取？从而不知道事务有没有写入？
- 读操作会获取数据的时间戳，但是未提交的写操作没有被分配时间戳
- 该事务的读操作使用伤停等待避免死锁
- 客户端将赌球请求发给副本，并获取读取锁，从而拿到最新数据
- 客户端完成读取，然后缓冲写入？开始两阶段提交

## TODO 两阶段提交
- https://en.wikipedia.org/wiki/Two-phase_commit_protocol
- 为了事务提交的一致性
- 每个节点只能知道自己的操作是否成功，无法知道其他节点的状态
- 如果一个事务跨越多个节点，为了保证事务的ACID，需要引入一个协调者
- 让参与者将WAL结果通知协调者，然后协调者根据结果，觉得参与者是提交还是终止
- 区别于用来并发控制的两阶段锁

## 0926

## 6.824 2021 Lecture 14 - Spanner

## 需求
- 广域网分布式事务的罕见用例
- 两阶段提交看起来慢，容易阻塞
- 解决办法，基于Paxos两阶段提交
- 异步时间来解决快速的只读事务
- 最新数据应该比本地副本的权限更高

## 用例
- F1 广告系统，替代 BigTable
- 更快的异步复制，灵活的分区，跨分区事务
- TODO-Table-6: 负载以只读事务为主
- 要求强一致性，外部一致性，可线性化，可序列化

## 分区
- 每个分区对应Paxos组，副本都在不同的数据中心
- 分区可以通过并行实现搞吞吐
- 客户端可以很快的读取本地副本
- 可以在客户附近部署副本

## 读写事务
- 基于Paxos 副本的两阶段提交
- 客户端获取全局唯一的事务ID，然后把请求发送给相关分区的 Paxos 主节点

## 只读事务
- TODO

## 术语
- prone，易于
- neat，巧妙

## 0928

## 两阶段锁
- 保证了可可线性化，
- 希望只读事务比读写事务快得多
- 从本地数据中心读取，不用锁和两阶段提交

## 外部一致性
- 事务1在事务2之前完成，事务2必须看到事务1的写入
- 时间的比较使用真时间接口
- 事务实现可线性化

## 事务并发的问题
- 脏读，Dirty Read，会话2没读到会话1写入的内容
- TODO：不可重复读，Non-repeatable Read
- 幻读，Phantom，读出两条记录

## 四个隔离级别
- 读未提交 < 读已提交 < 可重复读 < 可串行化
- 由低到高，隔离级别越高，性能影响越大
- 默认隔离界别是可重复读

## 级别1 - 读未提交，Read Uncommitted
- 事务A可以读到事务B修改过，但未提交的数据
- 可能发生脏读，不可重读读，和幻读
- 很少使用此级别

## 级别2 - 读已提交
- 事务B只能在事务A已经提交后才能事务A的数据
- 此级别解决了脏读的问题，不能解决不可重复读和幻读的问题

## 级别3 - 可重复读
- 事务B只能在自己的事务提交后，才能读到事务A已经提价的数据
- 此级别解决了脏读和不可重复读的问题，但不能解决幻读的问题
- TODO-MVCC，多版本并发机制

## 级别4 - 可串行化
- 相当于单线程，后一个事务必须等前一个事务结束后才能执行


